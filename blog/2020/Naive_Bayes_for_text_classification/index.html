<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Arnau  Jimenez Castany | Naive Bayes for text classification</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2020/Naive_Bayes_for_text_classification/">

<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-187141110-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-187141110-1');
  </script>


    
<!-- MathJax -->
<script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        tags: 'ams'
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Arnau</span>   Jimenez Castany
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/videos/">
                multimedia
                
              </a>
          </li>
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Naive Bayes for text classification</h1>
    <p class="post-meta">November 11, 2020</p>
  </header>

  <article class="post-content">
    <h2 id="1-goal">1. Goal</h2>
<p>Given a series of classes $C_i$ compute the probability that a sequence of words $\{w_1, w_2, \ldots , w_n\}$ belongs to the class $C_i$. Mathematically:</p>

<p>\begin{equation}
P(C_i\mid w_1, w_2, \ldots, w_n) 
\label{eq:goal}
\end{equation}</p>

<!--more-->

<h2 id="2-naive-assumption">2. <em>Naive</em> Assumption</h2>

<p>We assume that in <strong>each class</strong> the words are <strong>independent</strong> from each other:</p>

<p>\begin{equation}
P(w_1, w_2, \ldots, w_n \mid C_i) = \prod_{j=1}^n P(w_j \mid C_i) \iff  \text{Words are independent in each class}
 \label{eq:assumption}
\end{equation}</p>

<p>That is clearly not completely true, there are correlations between words, but we will assume there are not.</p>

<p>This simplifies enormously the analysis and computations—that is why it is widely used. On the other hand this assumption can be too weak when what we try to compute depends on the semantics of the language. For example this model could not differentiate whatsoever between the following two sentences:</p>

<ul>
  <li>I know what I like</li>
  <li>I like what I know</li>
</ul>

<p>because both sentences contain the same words: for Naive Bayes Classifier the order of the words do <strong>not</strong> matter. If you are trying to do sentiment analysis Naive Bayes Classifier might not be the best option in terms of performance. Instead you can use <a href="https://www.kaggle.com/arnaujimnez/ulmfit-fastai-sentiment-analysis/data">ULMFit</a> or <a href="https://medium.com/towards-artificial-intelligence/text-classification-with-simple-transformers-a29d13358135">Transformers</a> if your model needs to capture more complex relations.</p>

<h2 id="3-computation-bayes-formula">3. Computation: Bayes’ formula</h2>

<p>As we said our goal was to estimate the probability that a sequence of words $\{w_1, w_2, \ldots , w_n\}$ belongs to the class $C_i$. But we want to use our naive Ansatz: here is where Bayes’ formula comes into play. We can rewritte equation \eqref{eq:goal} as:</p>

\[P(C_i\mid w_1, w_2, \ldots, w_n)  =  \frac{P( w_1, w_2, \ldots, w_n \mid C_i) P(C_i)}{P(w_1, w_2, \ldots, w_n)}\]

<p>remember this is still completely general, we have made no assumption so far. Now assume that the words in each class are independent (eq. \eqref{eq:assumption}):</p>

\[\implies P(C_i\mid w_1, w_2, \ldots, w_n)  = \frac{P(C_i)}{P(w_1, w_2, \ldots, w_n)}\prod_{j=1}^n P(w_j \mid C_i)\]

<p>This last equation is not general, but it is really useful because the quantities on the right of the equation are pretty easy to compute.
We have therefore translated the problem of computing $P(C_i\mid w_1, w_2, \ldots, w_n)$ to computing $P(C_i)$ and $P(w_j \mid C_i)$. The probability in the denominator is always ignored because it is a normalization factor and we are just interested in which of the conditional probabilites is the biggest. Both set of probabilites are easy to estimate:</p>

<ul>
  <li>The probability $P(w_j \mid C_i) $ is estimated as the frequency of word $w_j$  in category $C_i$:</li>
</ul>

\[P(w_j \mid C_i) := \frac{n^{(i)}_j}{N^{(i)}}\,  ,      \quad     N^{(i)} = \sum_j n^{(i)}_j\]

<p>      where $n^{(i)}_j$ is the number of times the word $w_j$ appears in the category $C_i$.</p>

<ul>
  <li>The probability $P(C_i) $  is the frequency of the category $i$ in the dataset.</li>
</ul>

<h2 id="4-subtleties">4. Subtleties</h2>
<p>If a word $w_k$ does not appear in class $C_i$ this makes the whole estimation to be zero:</p>

\[\implies P(C_i\mid w_1, w_2, \ldots, w_k, \ldots, w_n) \propto P(w_k \mid C_i) = 0\]

<p>In order to avoid this problem Laplace smoothing is used:</p>

\[P(w_j \mid C_i) := \frac{n^{(i)}_j +\alpha}{N^{(i)} + \alpha \cdot d}\,  ,      \quad     N^{(i)} = \sum_j n^{(i)}_j \, , \quad d = \# \,\text{ of different words in the whole dataset}\]

<p>and $\alpha=1$. Note that $\alpha$ could be any value bigger than zero.</p>

<h2 id="5-code-example">5. Code example</h2>

<h3 id="51-from-scratch">5.1 From Scratch</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="c1"># Load the dataset
</span><span class="n">data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">()</span>
<span class="c1"># Get the text categories
</span><span class="n">text_categories</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">target_names</span>
<span class="c1"># define the training set
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">"train"</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">text_categories</span><span class="p">)</span>
<span class="c1"># define the test set
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">"test"</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">text_categories</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">token_pattern</span><span class="o">=</span> <span class="s">'[a-zA-Z]+'</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">data</span><span class="p">[:])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># integer to word
</span><span class="n">i2o</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">()))</span>
<span class="c1"># word to integer
</span><span class="n">o2i</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">i2o</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">safe_sparse_dot</span>
<span class="n">smoothed_fc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X_train</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="o">==</span><span class="n">i</span><span class="p">].</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="p">)])</span>
<span class="n">words_per_class</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="o">==</span><span class="n">i</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="p">)]</span>
<span class="n">smoothed_cc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">w</span> <span class="o">+</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words_per_class</span><span class="p">])</span>
<span class="n">feature_log_prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">smoothed_fc</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">smoothed_cc</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">feature_log_prob</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="n">argmax</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>
<span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="o">==</span><span class="n">preds</span><span class="p">)</span><span class="o">/</span><span class="mi">50</span> 

</code></pre></div></div>

<h3 id="52-sklearn">5.2 Sklearn</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="c1"># Load the dataset
</span><span class="n">data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">()</span>
<span class="c1"># Get the text categories
</span><span class="n">text_categories</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">target_names</span>
<span class="c1"># define the training set
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">"train"</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">text_categories</span><span class="p">)</span>
<span class="c1"># define the test set
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">"test"</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">text_categories</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="c1"># Build the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(),</span> <span class="n">MultinomialNB</span><span class="p">())</span>
<span class="c1"># Train the model using the training data
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>
<span class="c1"># Predict the categories of the test data
</span><span class="n">predicted_categories</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># plot the confusion matrix
</span><span class="n">mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">predicted_categories</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">mat</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span> <span class="o">=</span> <span class="s">"d"</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">train_data</span><span class="p">.</span><span class="n">target_names</span><span class="p">,</span><span class="n">yticklabels</span><span class="o">=</span><span class="n">train_data</span><span class="p">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"true labels"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"predicted label"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The accuracy is {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">predicted_categories</span><span class="p">)))</span>

</code></pre></div></div>

<h2 id="references">References</h2>

<ul>
  <li>
    <p><a href="http://www.cs.columbia.edu/~mcollins/em.pdf">The Naive Bayes Model, Maximum-Likelihood
Estimation, and the EM Algorithm</a></p>
  </li>
  <li>
    <p><a href="http://www.cs.cmu.edu/~tom/10601_sp09/lectures/NBayes-1-28-2009-ann.pdf">Slide Lectures Naive Bayes</a></p>
  </li>
  <li>
    <p><a href="http://web.stanford.edu/class/cs109/lectureNotes/LN04_cond_bayes.pdf">Conditional Probability Lecture Notes</a></p>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a">Implemementing Naive Bayes in sklearn</a></p>
  </li>
</ul>


  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Arnau  Jimenez Castany.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
